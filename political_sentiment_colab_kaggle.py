# -*- coding: utf-8 -*-
"""political_sentiment_colab_kaggle.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QjmxNvGFc9IdcwTIsIi6LSp0SbcKk2rh

# Political News Sentiment Analysis (DistilBERT)
This notebook fine-tunes a pre-trained DistilBERT model for sentiment analysis on political news coverage.
"""

!pip -q install transformers datasets torch nltk scikit-learn matplotlib

import pandas as pd
import numpy as np
import nltk
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments
from datasets import Dataset
import torch, os

nltk.download('punkt')

from google.colab import files
uploaded = files.upload()

"""## Political News Headlines Dataset from Kaggle
This section loads the Political News Headlines Dataset from Kaggle.

"""

# Load CSV
df = pd.read_csv("uci-news-aggregator.csv", sep='\t', header=None,
                 names=['ID','TITLE','URL','PUBLISHER','CATEGORY','STORY','HOSTNAME','TIMESTAMP'])

# Preview dataset
df.head()

"""### Map categories to sentiment labels
The Kaggle dataset uses categories like `e` (entertainment), `b` (business), `t` (science/technology), `m` (health/medicine).

"""

# Human logic mapping of CATEGORY to sentiment

category_map = {
    'b': 'neutral',
    't': 'neutral',
    'e': 'positive',
    'm': 'negative'
}

df['label'] = df['CATEGORY'].map(category_map)

# Keep only relevant columns
df = df[['TITLE','label']].rename(columns={'TITLE':'text'})

# Drop missing or undefined labels
df = df.dropna(subset=['text','label']).copy()

df['label'].value_counts()

df = df.dropna(subset=['text','label']).copy()
df['text'] = df['text'].astype(str).str.strip()
df = df[df['text'].str.len() > 0]
df['label'] = df['label'].str.lower().str.strip()
df['label'].value_counts()

"""### Train/Validation split"""

train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])
train_df.shape, val_df.shape

"""### Encode labels"""

unique_labels = sorted(train_df['label'].unique())
label2id = {label:i for i,label in enumerate(unique_labels)}
id2label = {i:label for label,i in label2id.items()}
train_df['labels'] = train_df['label'].map(label2id)
val_df['labels'] = val_df['label'].map(label2id)
label2id, id2label

"""### Tokenize text"""

tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')

def tokenize_function(batch):
    return tokenizer(batch['text'], truncation=True, padding=True, max_length=256)

train_ds = Dataset.from_pandas(train_df[['text','labels']])
val_ds = Dataset.from_pandas(val_df[['text','labels']])
train_ds = train_ds.map(tokenize_function, batched=True)
val_ds = val_ds.map(tokenize_function, batched=True)

train_ds = train_ds.remove_columns(['text'])
val_ds = val_ds.remove_columns(['text'])

train_ds.set_format(type='torch', columns=['input_ids','attention_mask','labels'])
val_ds.set_format(type='torch', columns=['input_ids','attention_mask','labels'])
len(train_ds), len(val_ds)

"""### Load model"""

model = DistilBertForSequenceClassification.from_pretrained(
    'distilbert-base-uncased',
    num_labels=len(unique_labels),
    id2label=id2label,
    label2id=label2id
)

"""### Training arguments"""

training_args = TrainingArguments(
    output_dir='./results',
    eval_strategy='epoch', # Changed from evaluation_strategy
    save_strategy='epoch',
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=3,
    weight_decay=0.01,
    logging_steps=10,
    load_best_model_at_end=True,
    metric_for_best_model='f1',
    greater_is_better=True,
    report_to="none" # Disable Weights & Biases logging
)

"""### Metrics & Trainer"""

def compute_metrics(eval_pred):
    logits, labels = eval_pred
    preds = np.argmax(logits, axis=1)
    return {
        'accuracy': accuracy_score(labels, preds),
        'f1': f1_score(labels, preds, average='weighted'),
        'precision': precision_score(labels, preds, average='weighted'),
        'recall': recall_score(labels, preds, average='weighted'),
    }

from transformers import Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_ds,
    eval_dataset=val_ds,
    compute_metrics=compute_metrics
)

"""### Train"""

trainer.train()

"""### Evaluate"""

metrics = trainer.evaluate(); metrics

"""### Confusion Matrix"""

preds_output = trainer.predict(val_ds)
preds = np.argmax(preds_output.predictions, axis=1)

import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

cm = confusion_matrix(val_df['labels'], preds)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[id2label[i] for i in range(len(unique_labels))])
fig, ax = plt.subplots(figsize=(6,6))
disp.plot(ax=ax)
plt.title("Confusion Matrix - Political Sentiment")
plt.show()

"""### Save model and label mapping"""

import os, json
save_dir = "./model_out"
os.makedirs(save_dir, exist_ok=True)
trainer.save_model(save_dir)
with open(os.path.join(save_dir, "label2id.json"), "w") as f:
    json.dump(label2id, f)
with open(os.path.join(save_dir, "id2label.json"), "w") as f:
    json.dump(id2label, f)
print("Saved to", save_dir)

"""### Inference examples"""

from transformers import TextClassificationPipeline
pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=False)

examples = [
    "Government announces relief for small businesses.",
    "Critics slammed the administration for mishandling the crisis.",
    "Officials met to discuss the policy; outcome remains uncertain."
]
for t in examples:
    print(t, "->", pipe(t))